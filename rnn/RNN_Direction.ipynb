{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "YFnGBVmoeY3d"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import joblib as jb\n",
        "import joblib\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'e:\\\\Codes\\\\Mantis-Shrimp-Eye-s-Collision-Avoidance\\\\rnn'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'e:\\\\Codes\\\\Mantis-Shrimp-Eye-s-Collision-Avoidance'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.chdir(\"../\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "sys.path.append(os.getcwd()+\"/tools\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from configmanager import ConfigurationManager\n",
        "configurationManager = ConfigurationManager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMJ5SN9zHnJw"
      },
      "source": [
        "# Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vCiFcuAzHS_b",
        "outputId": "5b1eb8a5-69f9-4f27-cde0-95866a793089"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>distance</th>\n",
              "      <th>x_center</th>\n",
              "      <th>x_pred</th>\n",
              "      <th>x_pred[0]</th>\n",
              "      <th>y_center</th>\n",
              "      <th>y_pred</th>\n",
              "      <th>y_pred[0]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.253262</td>\n",
              "      <td>617</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>242</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.253262</td>\n",
              "      <td>617</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>242</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.253262</td>\n",
              "      <td>617</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>242</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.253262</td>\n",
              "      <td>618</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>242</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.090219</td>\n",
              "      <td>618</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>243</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    distance  x_center x_pred  x_pred[0]  y_center y_pred  y_pred[0]\n",
              "0  11.253262       617      0        0.0       242      0        0.0\n",
              "1  11.253262       617      0        0.0       242      0        0.0\n",
              "2  11.253262       617      0        0.0       242      0        0.0\n",
              "3  11.253262       618      0        0.0       242      0        0.0\n",
              "4  11.090219       618      0        0.0       243      0        0.0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importing the training set\n",
        "\n",
        "dnn_rnn_dataset =  configurationManager.config_readable['dnn_rnn_dataset']\n",
        "rnn_trajectory_model_folder = configurationManager.config_readable['rnn_trajectory_model_folder']\n",
        "\n",
        "path_rnn_train = dnn_rnn_dataset+\"dnn_train.csv\"\n",
        "path_rnn_train = dnn_rnn_dataset+\"fake_train.csv\"\n",
        "\n",
        "\n",
        "dataset_train = pd.read_csv(path_rnn_train)\n",
        "\n",
        "\n",
        "dataset_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CE3fc3q30rmd"
      },
      "outputs": [],
      "source": [
        "def normalize_data(df_copy, train_ise_save_true_val_ise_false=False):\n",
        "    \n",
        "    sc = MinMaxScaler(feature_range = (0, 1))\n",
        "\n",
        "    for col in df_copy.columns:\n",
        "      df_copy[col] = sc.fit_transform(df_copy[col].values.reshape(-1,1))\n",
        "      if train_ise_save_true_val_ise_false:\n",
        "        scaler_filename = rnn_trajectory_model_folder+col+\"_transform.save\"\n",
        "        joblib.dump(sc, scaler_filename)\n",
        "    \n",
        "    '''\n",
        "    df_copy['y_pred'] = sc.fit_transform(df_copy['y_pred'].values.reshape(-1,1))\n",
        "    scaler_filename = normalization_path+ FILE_NAME+\"_y_pred_transform\"+\".save\"\n",
        "    joblib.dump(sc, scaler_filename)'''\n",
        "\n",
        "    return df_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UQNN_GeSzNKn",
        "outputId": "6abe3715-11ea-4f41-9efa-c0aa8d10ffcc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>distance</th>\n",
              "      <th>x_center</th>\n",
              "      <th>y_center</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11.253262</td>\n",
              "      <td>617</td>\n",
              "      <td>242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.253262</td>\n",
              "      <td>617</td>\n",
              "      <td>242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.253262</td>\n",
              "      <td>617</td>\n",
              "      <td>242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.253262</td>\n",
              "      <td>618</td>\n",
              "      <td>242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.090219</td>\n",
              "      <td>618</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11.079277</td>\n",
              "      <td>619</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11.079277</td>\n",
              "      <td>619</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11.090219</td>\n",
              "      <td>618</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11.079277</td>\n",
              "      <td>619</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11.079277</td>\n",
              "      <td>619</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    distance  x_center  y_center\n",
              "0  11.253262       617       242\n",
              "1  11.253262       617       242\n",
              "2  11.253262       617       242\n",
              "3  11.253262       618       242\n",
              "4  11.090219       618       243\n",
              "5  11.079277       619       243\n",
              "6  11.079277       619       243\n",
              "7  11.090219       618       243\n",
              "8  11.079277       619       243\n",
              "9  11.079277       619       243"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_train = dataset_train.iloc[:, [0,1 , 4]]\n",
        "dataset_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JA7s7CoGwkV",
        "outputId": "1cee01cd-94f1-41fc-cf5a-34b57a9ca4cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 11.25326237, 617.        , 242.        ],\n",
              "       [ 11.25326237, 617.        , 242.        ],\n",
              "       [ 11.25326237, 617.        , 242.        ],\n",
              "       ...,\n",
              "       [  8.05739399, 954.        , 277.        ],\n",
              "       [  7.96557936, 956.        , 278.        ],\n",
              "       [  8.05739399, 957.        , 277.        ]])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set = dataset_train.values\n",
        "training_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ4Ks62xvmhA",
        "outputId": "f1ea300d-c949-4a59-fa30-c3d6c80a2e9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(training_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sObY2JFRoFfG",
        "outputId": "8e900ff0-372c-4a3f-925a-90c0b9861625"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.21.6'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "np.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNQOGxkcuwYl",
        "outputId": "c70169d9-6a67-46f5-88fe-2fa20ac1ae18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(343, 3)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo-w_83qvH8s",
        "outputId": "51bff238-7b55-47b5-ae1e-8d3152e0b8a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 11.25326237, 617.        , 242.        ],\n",
              "       [ 11.25326237, 617.        , 242.        ],\n",
              "       [ 11.25326237, 617.        , 242.        ],\n",
              "       [ 11.25326237, 618.        , 242.        ],\n",
              "       [ 11.09021885, 618.        , 243.        ],\n",
              "       [ 11.07927732, 619.        , 243.        ],\n",
              "       [ 11.07927732, 619.        , 243.        ],\n",
              "       [ 11.09021885, 618.        , 243.        ],\n",
              "       [ 11.07927732, 619.        , 243.        ],\n",
              "       [ 11.07927732, 619.        , 243.        ]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7ljoQk-tnur",
        "outputId": "57c22f10-2501-4e6a-e6db-b19b577bf316"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(training_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TXuJJxRXII4M"
      },
      "outputs": [],
      "source": [
        "training_set_scaled = normalize_data(dataset_train.copy(),train_ise_save_true_val_ise_false=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tv39dQNIcLN",
        "outputId": "281ce9c2-e35b-428d-bdf6-6131018f4504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.44701987 0.44288079 0.44039735 0.43625828 0.43211921 0.4263245\n",
            " 0.42218543 0.41390728 0.41142384 0.40645695]\n",
            "[0.44288079 0.44039735 0.43625828 0.43211921 0.4263245  0.42218543\n",
            " 0.41390728 0.41142384 0.40645695 0.40149007]\n",
            "[0.44039735 0.43625828 0.43211921 0.4263245  0.42218543 0.41390728\n",
            " 0.41142384 0.40645695 0.40149007 0.39569536]\n",
            "[0.43625828 0.43211921 0.4263245  0.42218543 0.41390728 0.41142384\n",
            " 0.40645695 0.40149007 0.39569536 0.38907285]\n",
            "[0.43211921 0.4263245  0.42218543 0.41390728 0.41142384 0.40645695\n",
            " 0.40149007 0.39569536 0.38907285 0.38576159]\n",
            "[0.4263245  0.42218543 0.41390728 0.41142384 0.40645695 0.40149007\n",
            " 0.39569536 0.38907285 0.38576159 0.37748344]\n",
            "[0.42218543 0.41390728 0.41142384 0.40645695 0.40149007 0.39569536\n",
            " 0.38907285 0.38576159 0.37748344 0.37251656]\n",
            "[0.41390728 0.41142384 0.40645695 0.40149007 0.39569536 0.38907285\n",
            " 0.38576159 0.37748344 0.37251656 0.36837748]\n",
            "[0.41142384 0.40645695 0.40149007 0.39569536 0.38907285 0.38576159\n",
            " 0.37748344 0.37251656 0.36837748 0.35927152]\n",
            "[0.40645695 0.40149007 0.39569536 0.38907285 0.38576159 0.37748344\n",
            " 0.37251656 0.36837748 0.35927152 0.35347682]\n",
            "[0.40149007 0.39569536 0.38907285 0.38576159 0.37748344 0.37251656\n",
            " 0.36837748 0.35927152 0.35347682 0.34768212]\n",
            "[0.39569536 0.38907285 0.38576159 0.37748344 0.37251656 0.36837748\n",
            " 0.35927152 0.35347682 0.34768212 0.3410596 ]\n",
            "[0.38907285 0.38576159 0.37748344 0.37251656 0.36837748 0.35927152\n",
            " 0.35347682 0.34768212 0.3410596  0.3352649 ]\n",
            "[0.38576159 0.37748344 0.37251656 0.36837748 0.35927152 0.35347682\n",
            " 0.34768212 0.3410596  0.3352649  0.3352649 ]\n",
            "[0.37748344 0.37251656 0.36837748 0.35927152 0.35347682 0.34768212\n",
            " 0.3410596  0.3352649  0.3352649  0.3294702 ]\n",
            "[0.37251656 0.36837748 0.35927152 0.35347682 0.34768212 0.3410596\n",
            " 0.3352649  0.3352649  0.3294702  0.32201987]\n",
            "[0.36837748 0.35927152 0.35347682 0.34768212 0.3410596  0.3352649\n",
            " 0.3352649  0.3294702  0.32201987 0.31705298]\n",
            "[0.35927152 0.35347682 0.34768212 0.3410596  0.3352649  0.3352649\n",
            " 0.3294702  0.32201987 0.31705298 0.30877483]\n",
            "[0.35347682 0.34768212 0.3410596  0.3352649  0.3352649  0.3294702\n",
            " 0.32201987 0.31705298 0.30877483 0.30049669]\n",
            "[0.34768212 0.3410596  0.3352649  0.3352649  0.3294702  0.32201987\n",
            " 0.31705298 0.30877483 0.30049669 0.29387417]\n",
            "[0.3410596  0.3352649  0.3352649  0.3294702  0.32201987 0.31705298\n",
            " 0.30877483 0.30049669 0.29387417 0.28559603]\n",
            "[0.3352649  0.3352649  0.3294702  0.32201987 0.31705298 0.30877483\n",
            " 0.30049669 0.29387417 0.28559603 0.2781457 ]\n",
            "[0.3352649  0.3294702  0.32201987 0.31705298 0.30877483 0.30049669\n",
            " 0.29387417 0.28559603 0.2781457  0.27235099]\n",
            "[0.3294702  0.32201987 0.31705298 0.30877483 0.30049669 0.29387417\n",
            " 0.28559603 0.2781457  0.27235099 0.26407285]\n",
            "[0.32201987 0.31705298 0.30877483 0.30049669 0.29387417 0.28559603\n",
            " 0.2781457  0.27235099 0.26407285 0.25745033]\n",
            "[0.31705298 0.30877483 0.30049669 0.29387417 0.28559603 0.2781457\n",
            " 0.27235099 0.26407285 0.25745033 0.24751656]\n",
            "[0.30877483 0.30049669 0.29387417 0.28559603 0.2781457  0.27235099\n",
            " 0.26407285 0.25745033 0.24751656 0.24006623]\n",
            "[0.30049669 0.29387417 0.28559603 0.2781457  0.27235099 0.26407285\n",
            " 0.25745033 0.24751656 0.24006623 0.23261589]\n",
            "[0.29387417 0.28559603 0.2781457  0.27235099 0.26407285 0.25745033\n",
            " 0.24751656 0.24006623 0.23261589 0.22516556]\n",
            "[0.28559603 0.2781457  0.27235099 0.26407285 0.25745033 0.24751656\n",
            " 0.24006623 0.23261589 0.22516556 0.21192053]\n",
            "[0.2781457  0.27235099 0.26407285 0.25745033 0.24751656 0.24006623\n",
            " 0.23261589 0.22516556 0.21192053 0.20778146]\n",
            "[0.27235099 0.26407285 0.25745033 0.24751656 0.24006623 0.23261589\n",
            " 0.22516556 0.21192053 0.20778146 0.19784768]\n",
            "[0.26407285 0.25745033 0.24751656 0.24006623 0.23261589 0.22516556\n",
            " 0.21192053 0.20778146 0.19784768 0.19288079]\n",
            "[0.25745033 0.24751656 0.24006623 0.23261589 0.22516556 0.21192053\n",
            " 0.20778146 0.19784768 0.19288079 0.18211921]\n",
            "[0.24751656 0.24006623 0.23261589 0.22516556 0.21192053 0.20778146\n",
            " 0.19784768 0.19288079 0.18211921 0.17135762]\n",
            "[0.24006623 0.23261589 0.22516556 0.21192053 0.20778146 0.19784768\n",
            " 0.19288079 0.18211921 0.17135762 0.16556291]\n",
            "[0.23261589 0.22516556 0.21192053 0.20778146 0.19784768 0.19288079\n",
            " 0.18211921 0.17135762 0.16556291 0.15811258]\n",
            "[0.22516556 0.21192053 0.20778146 0.19784768 0.19288079 0.18211921\n",
            " 0.17135762 0.16556291 0.15811258 0.14983444]\n",
            "[0.21192053 0.20778146 0.19784768 0.19288079 0.18211921 0.17135762\n",
            " 0.16556291 0.15811258 0.14983444 0.14983444]\n",
            "[0.20778146 0.19784768 0.19288079 0.18211921 0.17135762 0.16556291\n",
            " 0.15811258 0.14983444 0.14983444 0.13907285]\n",
            "[0.19784768 0.19288079 0.18211921 0.17135762 0.16556291 0.15811258\n",
            " 0.14983444 0.14983444 0.13907285 0.12334437]\n",
            "[0.19288079 0.18211921 0.17135762 0.16556291 0.15811258 0.14983444\n",
            " 0.14983444 0.13907285 0.12334437 0.1192053 ]\n",
            "[0.18211921 0.17135762 0.16556291 0.15811258 0.14983444 0.14983444\n",
            " 0.13907285 0.12334437 0.1192053  0.11672185]\n",
            "[0.17135762 0.16556291 0.15811258 0.14983444 0.14983444 0.13907285\n",
            " 0.12334437 0.1192053  0.11672185 0.10927152]\n",
            "[0.16556291 0.15811258 0.14983444 0.14983444 0.13907285 0.12334437\n",
            " 0.1192053  0.11672185 0.10927152 0.10347682]\n",
            "[0.15811258 0.14983444 0.14983444 0.13907285 0.12334437 0.1192053\n",
            " 0.11672185 0.10927152 0.10347682 0.06125828]\n",
            "[0.14983444 0.14983444 0.13907285 0.12334437 0.1192053  0.11672185\n",
            " 0.10927152 0.10347682 0.06125828 0.05463576]\n",
            "[0.14983444 0.13907285 0.12334437 0.1192053  0.11672185 0.10927152\n",
            " 0.10347682 0.06125828 0.05463576 0.04635762]\n",
            "[0.13907285 0.12334437 0.1192053  0.11672185 0.10927152 0.10347682\n",
            " 0.06125828 0.05463576 0.04635762 0.04387417]\n",
            "[0.12334437 0.1192053  0.11672185 0.10927152 0.10347682 0.06125828\n",
            " 0.05463576 0.04635762 0.04387417 0.0339404 ]\n",
            "[0.1192053  0.11672185 0.10927152 0.10347682 0.06125828 0.05463576\n",
            " 0.04635762 0.04387417 0.0339404  0.02235099]\n",
            "[0.11672185 0.10927152 0.10347682 0.06125828 0.05463576 0.04635762\n",
            " 0.04387417 0.0339404  0.02235099 0.01572848]\n",
            "[0.10927152 0.10347682 0.06125828 0.05463576 0.04635762 0.04387417\n",
            " 0.0339404  0.02235099 0.01572848 0.        ]\n",
            "[0.10347682 0.06125828 0.05463576 0.04635762 0.04387417 0.0339404\n",
            " 0.02235099 0.01572848 0.         0.00331126]\n",
            "[0.06125828 0.05463576 0.04635762 0.04387417 0.0339404  0.02235099\n",
            " 0.01572848 0.         0.00331126 0.00331126]\n",
            "[0.05463576 0.04635762 0.04387417 0.0339404  0.02235099 0.01572848\n",
            " 0.         0.00331126 0.00331126 0.01572848]\n",
            "[0.04635762 0.04387417 0.0339404  0.02235099 0.01572848 0.\n",
            " 0.00331126 0.00331126 0.01572848 0.01903974]\n",
            "[0.04387417 0.0339404  0.02235099 0.01572848 0.         0.00331126\n",
            " 0.00331126 0.01572848 0.01903974 0.01821192]\n",
            "[0.0339404  0.02235099 0.01572848 0.         0.00331126 0.00331126\n",
            " 0.01572848 0.01903974 0.01821192 0.02235099]\n",
            "[0.02235099 0.01572848 0.         0.00331126 0.00331126 0.01572848\n",
            " 0.01903974 0.01821192 0.02235099 0.03145695]\n",
            "[0.01572848 0.         0.00331126 0.00331126 0.01572848 0.01903974\n",
            " 0.01821192 0.02235099 0.03145695 0.0339404 ]\n",
            "[0.         0.00331126 0.00331126 0.01572848 0.01903974 0.01821192\n",
            " 0.02235099 0.03145695 0.0339404  0.03476821]\n",
            "[0.00331126 0.00331126 0.01572848 0.01903974 0.01821192 0.02235099\n",
            " 0.03145695 0.0339404  0.03476821 0.03476821]\n",
            "[0.00331126 0.01572848 0.01903974 0.01821192 0.02235099 0.03145695\n",
            " 0.0339404  0.03476821 0.03476821 0.03145695]\n",
            "[0.01572848 0.01903974 0.01821192 0.02235099 0.03145695 0.0339404\n",
            " 0.03476821 0.03476821 0.03145695 0.03311258]\n",
            "[0.01903974 0.01821192 0.02235099 0.03145695 0.0339404  0.03476821\n",
            " 0.03476821 0.03145695 0.03311258 0.03062914]\n",
            "[0.01821192 0.02235099 0.03145695 0.0339404  0.03476821 0.03476821\n",
            " 0.03145695 0.03311258 0.03062914 0.02731788]\n",
            "[0.02235099 0.03145695 0.0339404  0.03476821 0.03476821 0.03145695\n",
            " 0.03311258 0.03062914 0.02731788 0.02897351]\n",
            "[0.03145695 0.0339404  0.03476821 0.03476821 0.03145695 0.03311258\n",
            " 0.03062914 0.02731788 0.02897351 0.02897351]\n",
            "[0.0339404  0.03476821 0.03476821 0.03145695 0.03311258 0.03062914\n",
            " 0.02731788 0.02897351 0.02897351 0.09850993]\n",
            "[0.03476821 0.03476821 0.03145695 0.03311258 0.03062914 0.02731788\n",
            " 0.02897351 0.02897351 0.09850993 0.10182119]\n",
            "[0.03476821 0.03145695 0.03311258 0.03062914 0.02731788 0.02897351\n",
            " 0.02897351 0.09850993 0.10182119 0.10430464]\n",
            "[0.03145695 0.03311258 0.03062914 0.02731788 0.02897351 0.02897351\n",
            " 0.09850993 0.10182119 0.10430464 0.10596026]\n",
            "[0.03311258 0.03062914 0.02731788 0.02897351 0.02897351 0.09850993\n",
            " 0.10182119 0.10430464 0.10596026 0.11175497]\n",
            "[0.03062914 0.02731788 0.02897351 0.02897351 0.09850993 0.10182119\n",
            " 0.10430464 0.10596026 0.11175497 0.13576159]\n",
            "[0.02731788 0.02897351 0.02897351 0.09850993 0.10182119 0.10430464\n",
            " 0.10596026 0.11175497 0.13576159 0.14652318]\n",
            "[0.02897351 0.02897351 0.09850993 0.10182119 0.10430464 0.10596026\n",
            " 0.11175497 0.13576159 0.14652318 0.15480132]\n",
            "[0.02897351 0.09850993 0.10182119 0.10430464 0.10596026 0.11175497\n",
            " 0.13576159 0.14652318 0.15480132 0.1647351 ]\n",
            "[0.09850993 0.10182119 0.10430464 0.10596026 0.11175497 0.13576159\n",
            " 0.14652318 0.15480132 0.1647351  0.17218543]\n",
            "[0.10182119 0.10430464 0.10596026 0.11175497 0.13576159 0.14652318\n",
            " 0.15480132 0.1647351  0.17218543 0.18294702]\n",
            "[0.10430464 0.10596026 0.11175497 0.13576159 0.14652318 0.15480132\n",
            " 0.1647351  0.17218543 0.18294702 0.19288079]\n",
            "[0.10596026 0.11175497 0.13576159 0.14652318 0.15480132 0.1647351\n",
            " 0.17218543 0.18294702 0.19288079 0.20115894]\n",
            "[0.11175497 0.13576159 0.14652318 0.15480132 0.1647351  0.17218543\n",
            " 0.18294702 0.19288079 0.20115894 0.21109272]\n",
            "[0.13576159 0.14652318 0.15480132 0.1647351  0.17218543 0.18294702\n",
            " 0.19288079 0.20115894 0.21109272 0.22350993]\n",
            "[0.14652318 0.15480132 0.1647351  0.17218543 0.18294702 0.19288079\n",
            " 0.20115894 0.21109272 0.22350993 0.23427152]\n",
            "[0.15480132 0.1647351  0.17218543 0.18294702 0.19288079 0.20115894\n",
            " 0.21109272 0.22350993 0.23427152 0.24172185]\n",
            "[0.1647351  0.17218543 0.18294702 0.19288079 0.20115894 0.21109272\n",
            " 0.22350993 0.23427152 0.24172185 0.25248344]\n",
            "[0.17218543 0.18294702 0.19288079 0.20115894 0.21109272 0.22350993\n",
            " 0.23427152 0.24172185 0.25248344 0.26324503]\n",
            "[0.18294702 0.19288079 0.20115894 0.21109272 0.22350993 0.23427152\n",
            " 0.24172185 0.25248344 0.26324503 0.27566225]\n",
            "[0.19288079 0.20115894 0.21109272 0.22350993 0.23427152 0.24172185\n",
            " 0.25248344 0.26324503 0.27566225 0.28559603]\n",
            "[0.20115894 0.21109272 0.22350993 0.23427152 0.24172185 0.25248344\n",
            " 0.26324503 0.27566225 0.28559603 0.28559603]\n",
            "[0.21109272 0.22350993 0.23427152 0.24172185 0.25248344 0.26324503\n",
            " 0.27566225 0.28559603 0.28559603 0.29304636]\n",
            "[0.22350993 0.23427152 0.24172185 0.25248344 0.26324503 0.27566225\n",
            " 0.28559603 0.28559603 0.29304636 0.30463576]\n",
            "[0.23427152 0.24172185 0.25248344 0.26324503 0.27566225 0.28559603\n",
            " 0.28559603 0.29304636 0.30463576 0.31788079]\n",
            "[0.24172185 0.25248344 0.26324503 0.27566225 0.28559603 0.28559603\n",
            " 0.29304636 0.30463576 0.31788079 0.3294702 ]\n",
            "[0.25248344 0.26324503 0.27566225 0.28559603 0.28559603 0.29304636\n",
            " 0.30463576 0.31788079 0.3294702  0.33940397]\n",
            "[0.26324503 0.27566225 0.28559603 0.28559603 0.29304636 0.30463576\n",
            " 0.31788079 0.3294702  0.33940397 0.35016556]\n",
            "[0.27566225 0.28559603 0.28559603 0.29304636 0.30463576 0.31788079\n",
            " 0.3294702  0.33940397 0.35016556 0.35761589]\n",
            "[0.28559603 0.28559603 0.29304636 0.30463576 0.31788079 0.3294702\n",
            " 0.33940397 0.35016556 0.35761589 0.37168874]\n",
            "[0.28559603 0.29304636 0.30463576 0.31788079 0.3294702  0.33940397\n",
            " 0.35016556 0.35761589 0.37168874 0.38576159]\n",
            "[0.29304636 0.30463576 0.31788079 0.3294702  0.33940397 0.35016556\n",
            " 0.35761589 0.37168874 0.38576159 0.39652318]\n",
            "[0.30463576 0.31788079 0.3294702  0.33940397 0.35016556 0.35761589\n",
            " 0.37168874 0.38576159 0.39652318 0.40645695]\n",
            "[0.31788079 0.3294702  0.33940397 0.35016556 0.35761589 0.37168874\n",
            " 0.38576159 0.39652318 0.40645695 0.41887417]\n",
            "[0.3294702  0.33940397 0.35016556 0.35761589 0.37168874 0.38576159\n",
            " 0.39652318 0.40645695 0.41887417 0.42880795]\n",
            "[0.33940397 0.35016556 0.35761589 0.37168874 0.38576159 0.39652318\n",
            " 0.40645695 0.41887417 0.42880795 0.44122517]\n",
            "[0.35016556 0.35761589 0.37168874 0.38576159 0.39652318 0.40645695\n",
            " 0.41887417 0.42880795 0.44122517 0.45364238]\n",
            "[0.35761589 0.37168874 0.38576159 0.39652318 0.40645695 0.41887417\n",
            " 0.42880795 0.44122517 0.45364238 0.4660596 ]\n",
            "[0.37168874 0.38576159 0.39652318 0.40645695 0.41887417 0.42880795\n",
            " 0.44122517 0.45364238 0.4660596  0.47764901]\n",
            "[0.38576159 0.39652318 0.40645695 0.41887417 0.42880795 0.44122517\n",
            " 0.45364238 0.4660596  0.47764901 0.48923841]\n",
            "[0.39652318 0.40645695 0.41887417 0.42880795 0.44122517 0.45364238\n",
            " 0.4660596  0.47764901 0.48923841 0.49834437]\n",
            "[0.40645695 0.41887417 0.42880795 0.44122517 0.45364238 0.4660596\n",
            " 0.47764901 0.48923841 0.49834437 0.50993377]\n",
            "[0.41887417 0.42880795 0.44122517 0.45364238 0.4660596  0.47764901\n",
            " 0.48923841 0.49834437 0.50993377 0.52483444]\n",
            "[0.42880795 0.44122517 0.45364238 0.4660596  0.47764901 0.48923841\n",
            " 0.49834437 0.50993377 0.52483444 0.53476821]\n",
            "[0.44122517 0.45364238 0.4660596  0.47764901 0.48923841 0.49834437\n",
            " 0.50993377 0.52483444 0.53476821 0.54635762]\n",
            "[0.45364238 0.4660596  0.47764901 0.48923841 0.49834437 0.50993377\n",
            " 0.52483444 0.53476821 0.54635762 0.56043046]\n",
            "[0.4660596  0.47764901 0.48923841 0.49834437 0.50993377 0.52483444\n",
            " 0.53476821 0.54635762 0.56043046 0.56043046]\n",
            "[0.47764901 0.48923841 0.49834437 0.50993377 0.52483444 0.53476821\n",
            " 0.54635762 0.56043046 0.56043046 0.57119205]\n",
            "[0.48923841 0.49834437 0.50993377 0.52483444 0.53476821 0.54635762\n",
            " 0.56043046 0.56043046 0.57119205 0.58360927]\n",
            "[0.49834437 0.50993377 0.52483444 0.53476821 0.54635762 0.56043046\n",
            " 0.56043046 0.57119205 0.58360927 0.59354305]\n",
            "[0.50993377 0.52483444 0.53476821 0.54635762 0.56043046 0.56043046\n",
            " 0.57119205 0.58360927 0.59354305 0.60678808]\n",
            "[0.52483444 0.53476821 0.54635762 0.56043046 0.56043046 0.57119205\n",
            " 0.58360927 0.59354305 0.60678808 0.61837748]\n",
            "[0.53476821 0.54635762 0.56043046 0.56043046 0.57119205 0.58360927\n",
            " 0.59354305 0.60678808 0.61837748 0.63245033]\n",
            "[0.54635762 0.56043046 0.56043046 0.57119205 0.58360927 0.59354305\n",
            " 0.60678808 0.61837748 0.63245033 0.64403974]\n",
            "[0.56043046 0.56043046 0.57119205 0.58360927 0.59354305 0.60678808\n",
            " 0.61837748 0.63245033 0.64403974 0.65728477]\n",
            "[0.56043046 0.57119205 0.58360927 0.59354305 0.60678808 0.61837748\n",
            " 0.63245033 0.64403974 0.65728477 0.66970199]\n",
            "[0.57119205 0.58360927 0.59354305 0.60678808 0.61837748 0.63245033\n",
            " 0.64403974 0.65728477 0.66970199 0.68211921]\n",
            "[0.58360927 0.59354305 0.60678808 0.61837748 0.63245033 0.64403974\n",
            " 0.65728477 0.66970199 0.68211921 0.69536424]\n",
            "[0.59354305 0.60678808 0.61837748 0.63245033 0.64403974 0.65728477\n",
            " 0.66970199 0.68211921 0.69536424 0.70695364]\n",
            "[0.60678808 0.61837748 0.63245033 0.64403974 0.65728477 0.66970199\n",
            " 0.68211921 0.69536424 0.70695364 0.72019868]\n",
            "[0.61837748 0.63245033 0.64403974 0.65728477 0.66970199 0.68211921\n",
            " 0.69536424 0.70695364 0.72019868 0.73261589]\n",
            "[0.63245033 0.64403974 0.65728477 0.66970199 0.68211921 0.69536424\n",
            " 0.70695364 0.72019868 0.73261589 0.74503311]\n",
            "[0.64403974 0.65728477 0.66970199 0.68211921 0.69536424 0.70695364\n",
            " 0.72019868 0.73261589 0.74503311 0.75827815]\n",
            "[0.65728477 0.66970199 0.68211921 0.69536424 0.70695364 0.72019868\n",
            " 0.73261589 0.74503311 0.75827815 0.77069536]\n",
            "[0.66970199 0.68211921 0.69536424 0.70695364 0.72019868 0.73261589\n",
            " 0.74503311 0.75827815 0.77069536 0.78228477]\n",
            "[0.68211921 0.69536424 0.70695364 0.72019868 0.73261589 0.74503311\n",
            " 0.75827815 0.77069536 0.78228477 0.79718543]\n",
            "[0.69536424 0.70695364 0.72019868 0.73261589 0.74503311 0.75827815\n",
            " 0.77069536 0.78228477 0.79718543 0.80794702]\n",
            "[0.70695364 0.72019868 0.73261589 0.74503311 0.75827815 0.77069536\n",
            " 0.78228477 0.79718543 0.80794702 0.82201987]\n",
            "[0.72019868 0.73261589 0.74503311 0.75827815 0.77069536 0.78228477\n",
            " 0.79718543 0.80794702 0.82201987 0.83278146]\n",
            "[0.73261589 0.74503311 0.75827815 0.77069536 0.78228477 0.79718543\n",
            " 0.80794702 0.82201987 0.83278146 0.8468543 ]\n",
            "[0.74503311 0.75827815 0.77069536 0.78228477 0.79718543 0.80794702\n",
            " 0.82201987 0.83278146 0.8468543  0.86092715]\n",
            "[0.75827815 0.77069536 0.78228477 0.79718543 0.80794702 0.82201987\n",
            " 0.83278146 0.8468543  0.86092715 0.87251656]\n",
            "[0.77069536 0.78228477 0.79718543 0.80794702 0.82201987 0.83278146\n",
            " 0.8468543  0.86092715 0.87251656 0.87168874]\n",
            "[0.78228477 0.79718543 0.80794702 0.82201987 0.83278146 0.8468543\n",
            " 0.86092715 0.87251656 0.87168874 0.88493377]\n",
            "[0.79718543 0.80794702 0.82201987 0.83278146 0.8468543  0.86092715\n",
            " 0.87251656 0.87168874 0.88493377 0.89735099]\n",
            "[0.80794702 0.82201987 0.83278146 0.8468543  0.86092715 0.87251656\n",
            " 0.87168874 0.88493377 0.89735099 0.91225166]\n",
            "[0.82201987 0.83278146 0.8468543  0.86092715 0.87251656 0.87168874\n",
            " 0.88493377 0.89735099 0.91225166 0.92466887]\n",
            "[0.83278146 0.8468543  0.86092715 0.87251656 0.87168874 0.88493377\n",
            " 0.89735099 0.91225166 0.92466887 0.93708609]\n",
            "[0.8468543  0.86092715 0.87251656 0.87168874 0.88493377 0.89735099\n",
            " 0.91225166 0.92466887 0.93708609 0.94950331]\n",
            "[0.86092715 0.87251656 0.87168874 0.88493377 0.89735099 0.91225166\n",
            " 0.92466887 0.93708609 0.94950331 0.96357616]\n",
            "[0.87251656 0.87168874 0.88493377 0.89735099 0.91225166 0.92466887\n",
            " 0.93708609 0.94950331 0.96357616 0.97433775]\n",
            "[0.87168874 0.88493377 0.89735099 0.91225166 0.92466887 0.93708609\n",
            " 0.94950331 0.96357616 0.97433775 0.99006623]\n",
            "[0.88493377 0.89735099 0.91225166 0.92466887 0.93708609 0.94950331\n",
            " 0.96357616 0.97433775 0.99006623 0.99917219]\n",
            "[0.89735099 0.91225166 0.92466887 0.93708609 0.94950331 0.96357616\n",
            " 0.97433775 0.99006623 0.99917219 1.        ]\n",
            "[0.91225166 0.92466887 0.93708609 0.94950331 0.96357616 0.97433775\n",
            " 0.99006623 0.99917219 1.         1.        ]\n",
            "[0.92466887 0.93708609 0.94950331 0.96357616 0.97433775 0.99006623\n",
            " 0.99917219 1.         1.         0.99751656]\n",
            "[0.93708609 0.94950331 0.96357616 0.97433775 0.99006623 0.99917219\n",
            " 1.         1.         0.99751656 0.98592715]\n",
            "[0.94950331 0.96357616 0.97433775 0.99006623 0.99917219 1.\n",
            " 1.         0.99751656 0.98592715 0.97599338]\n",
            "[0.96357616 0.97433775 0.99006623 0.99917219 1.         1.\n",
            " 0.99751656 0.98592715 0.97599338 0.96688742]\n",
            "[0.97433775 0.99006623 0.99917219 1.         1.         0.99751656\n",
            " 0.98592715 0.97599338 0.96688742 0.95281457]\n",
            "[0.99006623 0.99917219 1.         1.         0.99751656 0.98592715\n",
            " 0.97599338 0.96688742 0.95281457 0.93874172]\n",
            "[0.99917219 1.         1.         0.99751656 0.98592715 0.97599338\n",
            " 0.96688742 0.95281457 0.93874172 0.92880795]\n",
            "[1.         1.         0.99751656 0.98592715 0.97599338 0.96688742\n",
            " 0.95281457 0.93874172 0.92880795 0.91804636]\n",
            "[1.         0.99751656 0.98592715 0.97599338 0.96688742 0.95281457\n",
            " 0.93874172 0.92880795 0.91804636 0.90149007]\n",
            "[0.99751656 0.98592715 0.97599338 0.96688742 0.95281457 0.93874172\n",
            " 0.92880795 0.91804636 0.90149007 0.89072848]\n",
            "[0.98592715 0.97599338 0.96688742 0.95281457 0.93874172 0.92880795\n",
            " 0.91804636 0.90149007 0.89072848 0.8807947 ]\n",
            "[0.97599338 0.96688742 0.95281457 0.93874172 0.92880795 0.91804636\n",
            " 0.90149007 0.89072848 0.8807947  0.8634106 ]\n",
            "[0.96688742 0.95281457 0.93874172 0.92880795 0.91804636 0.90149007\n",
            " 0.89072848 0.8807947  0.8634106  0.85347682]\n",
            "[0.95281457 0.93874172 0.92880795 0.91804636 0.90149007 0.89072848\n",
            " 0.8807947  0.8634106  0.85347682 0.85347682]\n",
            "[0.93874172 0.92880795 0.91804636 0.90149007 0.89072848 0.8807947\n",
            " 0.8634106  0.85347682 0.85347682 0.8410596 ]\n",
            "[0.92880795 0.91804636 0.90149007 0.89072848 0.8807947  0.8634106\n",
            " 0.85347682 0.85347682 0.8410596  0.82284768]\n",
            "[0.91804636 0.90149007 0.89072848 0.8807947  0.8634106  0.85347682\n",
            " 0.85347682 0.8410596  0.82284768 0.81291391]\n",
            "[0.90149007 0.89072848 0.8807947  0.8634106  0.85347682 0.85347682\n",
            " 0.8410596  0.82284768 0.81291391 0.80380795]\n",
            "[0.89072848 0.8807947  0.8634106  0.85347682 0.85347682 0.8410596\n",
            " 0.82284768 0.81291391 0.80380795 0.78890728]\n",
            "[0.8807947  0.8634106  0.85347682 0.85347682 0.8410596  0.82284768\n",
            " 0.81291391 0.80380795 0.78890728 0.77317881]\n",
            "[0.8634106  0.85347682 0.85347682 0.8410596  0.82284768 0.81291391\n",
            " 0.80380795 0.78890728 0.77317881 0.76407285]\n",
            "[0.85347682 0.85347682 0.8410596  0.82284768 0.81291391 0.80380795\n",
            " 0.78890728 0.77317881 0.76407285 0.75      ]\n",
            "[0.85347682 0.8410596  0.82284768 0.81291391 0.80380795 0.78890728\n",
            " 0.77317881 0.76407285 0.75       0.73344371]\n",
            "[0.8410596  0.82284768 0.81291391 0.80380795 0.78890728 0.77317881\n",
            " 0.76407285 0.75       0.73344371 0.72268212]\n",
            "[0.82284768 0.81291391 0.80380795 0.78890728 0.77317881 0.76407285\n",
            " 0.75       0.73344371 0.72268212 0.70943709]\n",
            "[0.81291391 0.80380795 0.78890728 0.77317881 0.76407285 0.75\n",
            " 0.73344371 0.72268212 0.70943709 0.69288079]\n",
            "[0.80380795 0.78890728 0.77317881 0.76407285 0.75       0.73344371\n",
            " 0.72268212 0.70943709 0.69288079 0.68211921]\n",
            "[0.78890728 0.77317881 0.76407285 0.75       0.73344371 0.72268212\n",
            " 0.70943709 0.69288079 0.68211921 0.66639073]\n",
            "[0.77317881 0.76407285 0.75       0.73344371 0.72268212 0.70943709\n",
            " 0.69288079 0.68211921 0.66639073 0.65149007]\n",
            "[0.76407285 0.75       0.73344371 0.72268212 0.70943709 0.69288079\n",
            " 0.68211921 0.66639073 0.65149007 0.63990066]\n",
            "[0.75       0.73344371 0.72268212 0.70943709 0.69288079 0.68211921\n",
            " 0.66639073 0.65149007 0.63990066 0.61837748]\n",
            "[0.73344371 0.72268212 0.70943709 0.69288079 0.68211921 0.66639073\n",
            " 0.65149007 0.63990066 0.61837748 0.60927152]\n",
            "[0.72268212 0.70943709 0.69288079 0.68211921 0.66639073 0.65149007\n",
            " 0.63990066 0.61837748 0.60927152 0.5968543 ]\n",
            "[0.70943709 0.69288079 0.68211921 0.66639073 0.65149007 0.63990066\n",
            " 0.61837748 0.60927152 0.5968543  0.57864238]\n",
            "[0.69288079 0.68211921 0.66639073 0.65149007 0.63990066 0.61837748\n",
            " 0.60927152 0.5968543  0.57864238 0.56705298]\n",
            "[0.68211921 0.66639073 0.65149007 0.63990066 0.61837748 0.60927152\n",
            " 0.5968543  0.57864238 0.56705298 0.55215232]\n",
            "[0.66639073 0.65149007 0.63990066 0.61837748 0.60927152 0.5968543\n",
            " 0.57864238 0.56705298 0.55215232 0.53476821]\n",
            "[0.65149007 0.63990066 0.61837748 0.60927152 0.5968543  0.57864238\n",
            " 0.56705298 0.55215232 0.53476821 0.52235099]\n",
            "[0.63990066 0.61837748 0.60927152 0.5968543  0.57864238 0.56705298\n",
            " 0.55215232 0.53476821 0.52235099 0.52235099]\n",
            "[0.61837748 0.60927152 0.5968543  0.57864238 0.56705298 0.55215232\n",
            " 0.53476821 0.52235099 0.52235099 0.50745033]\n",
            "[0.60927152 0.5968543  0.57864238 0.56705298 0.55215232 0.53476821\n",
            " 0.52235099 0.52235099 0.50745033 0.49089404]\n",
            "[0.5968543  0.57864238 0.56705298 0.55215232 0.53476821 0.52235099\n",
            " 0.52235099 0.50745033 0.49089404 0.47930464]\n",
            "[0.57864238 0.56705298 0.55215232 0.53476821 0.52235099 0.52235099\n",
            " 0.50745033 0.49089404 0.47930464 0.46440397]\n",
            "[0.56705298 0.55215232 0.53476821 0.52235099 0.52235099 0.50745033\n",
            " 0.49089404 0.47930464 0.46440397 0.44701987]\n",
            "[0.55215232 0.53476821 0.52235099 0.52235099 0.50745033 0.49089404\n",
            " 0.47930464 0.46440397 0.44701987 0.43294702]\n",
            "[0.53476821 0.52235099 0.52235099 0.50745033 0.49089404 0.47930464\n",
            " 0.46440397 0.44701987 0.43294702 0.41556291]\n",
            "[0.52235099 0.52235099 0.50745033 0.49089404 0.47930464 0.46440397\n",
            " 0.44701987 0.43294702 0.41556291 0.40397351]\n",
            "[0.52235099 0.50745033 0.49089404 0.47930464 0.46440397 0.44701987\n",
            " 0.43294702 0.41556291 0.40397351 0.38824503]\n",
            "[0.50745033 0.49089404 0.47930464 0.46440397 0.44701987 0.43294702\n",
            " 0.41556291 0.40397351 0.38824503 0.37086093]\n",
            "[0.49089404 0.47930464 0.46440397 0.44701987 0.43294702 0.41556291\n",
            " 0.40397351 0.38824503 0.37086093 0.35844371]\n",
            "[0.47930464 0.46440397 0.44701987 0.43294702 0.41556291 0.40397351\n",
            " 0.38824503 0.37086093 0.35844371 0.34271523]\n",
            "[0.46440397 0.44701987 0.43294702 0.41556291 0.40397351 0.38824503\n",
            " 0.37086093 0.35844371 0.34271523 0.32615894]\n",
            "[0.44701987 0.43294702 0.41556291 0.40397351 0.38824503 0.37086093\n",
            " 0.35844371 0.34271523 0.32615894 0.31125828]\n",
            "[0.43294702 0.41556291 0.40397351 0.38824503 0.37086093 0.35844371\n",
            " 0.34271523 0.32615894 0.31125828 0.29304636]\n",
            "[0.41556291 0.40397351 0.38824503 0.37086093 0.35844371 0.34271523\n",
            " 0.32615894 0.31125828 0.29304636 0.28228477]\n",
            "[0.40397351 0.38824503 0.37086093 0.35844371 0.34271523 0.32615894\n",
            " 0.31125828 0.29304636 0.28228477 0.26655629]\n",
            "[0.38824503 0.37086093 0.35844371 0.34271523 0.32615894 0.31125828\n",
            " 0.29304636 0.28228477 0.26655629 0.24834437]\n",
            "[0.37086093 0.35844371 0.34271523 0.32615894 0.31125828 0.29304636\n",
            " 0.28228477 0.26655629 0.24834437 0.23509934]\n",
            "[0.35844371 0.34271523 0.32615894 0.31125828 0.29304636 0.28228477\n",
            " 0.26655629 0.24834437 0.23509934 0.21937086]\n",
            "[0.34271523 0.32615894 0.31125828 0.29304636 0.28228477 0.26655629\n",
            " 0.24834437 0.23509934 0.21937086 0.20033113]\n",
            "[0.32615894 0.31125828 0.29304636 0.28228477 0.26655629 0.24834437\n",
            " 0.23509934 0.21937086 0.20033113 0.18708609]\n",
            "[0.31125828 0.29304636 0.28228477 0.26655629 0.24834437 0.23509934\n",
            " 0.21937086 0.20033113 0.18708609 0.1705298 ]\n",
            "[0.29304636 0.28228477 0.26655629 0.24834437 0.23509934 0.21937086\n",
            " 0.20033113 0.18708609 0.1705298  0.15562914]\n",
            "[0.28228477 0.26655629 0.24834437 0.23509934 0.21937086 0.20033113\n",
            " 0.18708609 0.1705298  0.15562914 0.13990066]\n",
            "[0.26655629 0.24834437 0.23509934 0.21937086 0.20033113 0.18708609\n",
            " 0.1705298  0.15562914 0.13990066 0.14072848]\n",
            "[0.24834437 0.23509934 0.21937086 0.20033113 0.18708609 0.1705298\n",
            " 0.15562914 0.13990066 0.14072848 0.12417219]\n",
            "[0.23509934 0.21937086 0.20033113 0.18708609 0.1705298  0.15562914\n",
            " 0.13990066 0.14072848 0.12417219 0.10927152]\n",
            "[0.21937086 0.20033113 0.18708609 0.1705298  0.15562914 0.13990066\n",
            " 0.14072848 0.12417219 0.10927152 0.08443709]\n",
            "[0.20033113 0.18708609 0.1705298  0.15562914 0.13990066 0.14072848\n",
            " 0.12417219 0.10927152 0.08443709 0.07615894]\n",
            "[0.18708609 0.1705298  0.15562914 0.13990066 0.14072848 0.12417219\n",
            " 0.10927152 0.08443709 0.07615894 0.07450331]\n",
            "[0.1705298  0.15562914 0.13990066 0.14072848 0.12417219 0.10927152\n",
            " 0.08443709 0.07615894 0.07450331 0.02566225]\n",
            "[0.15562914 0.13990066 0.14072848 0.12417219 0.10927152 0.08443709\n",
            " 0.07615894 0.07450331 0.02566225 0.0339404 ]\n",
            "[0.13990066 0.14072848 0.12417219 0.10927152 0.08443709 0.07615894\n",
            " 0.07450331 0.02566225 0.0339404  0.02235099]\n",
            "[0.14072848 0.12417219 0.10927152 0.08443709 0.07615894 0.07450331\n",
            " 0.02566225 0.0339404  0.02235099 0.02566225]\n",
            "[0.12417219 0.10927152 0.08443709 0.07615894 0.07450331 0.02566225\n",
            " 0.0339404  0.02235099 0.02566225 0.02400662]\n",
            "[0.10927152 0.08443709 0.07615894 0.07450331 0.02566225 0.0339404\n",
            " 0.02235099 0.02566225 0.02400662 0.11754967]\n",
            "[0.08443709 0.07615894 0.07450331 0.02566225 0.0339404  0.02235099\n",
            " 0.02566225 0.02400662 0.11754967 0.12748344]\n",
            "[0.07615894 0.07450331 0.02566225 0.0339404  0.02235099 0.02566225\n",
            " 0.02400662 0.11754967 0.12748344 0.14072848]\n",
            "[0.07450331 0.02566225 0.0339404  0.02235099 0.02566225 0.02400662\n",
            " 0.11754967 0.12748344 0.14072848 0.15149007]\n",
            "[0.02566225 0.0339404  0.02235099 0.02566225 0.02400662 0.11754967\n",
            " 0.12748344 0.14072848 0.15149007 0.16142384]\n",
            "[0.0339404  0.02235099 0.02566225 0.02400662 0.11754967 0.12748344\n",
            " 0.14072848 0.15149007 0.16142384 0.17798013]\n",
            "[0.02235099 0.02566225 0.02400662 0.11754967 0.12748344 0.14072848\n",
            " 0.15149007 0.16142384 0.17798013 0.19039735]\n",
            "[0.02566225 0.02400662 0.11754967 0.12748344 0.14072848 0.15149007\n",
            " 0.16142384 0.17798013 0.19039735 0.20115894]\n",
            "[0.02400662 0.11754967 0.12748344 0.14072848 0.15149007 0.16142384\n",
            " 0.17798013 0.19039735 0.20115894 0.20115894]\n",
            "[0.11754967 0.12748344 0.14072848 0.15149007 0.16142384 0.17798013\n",
            " 0.19039735 0.20115894 0.20115894 0.21688742]\n",
            "[0.12748344 0.14072848 0.15149007 0.16142384 0.17798013 0.19039735\n",
            " 0.20115894 0.20115894 0.21688742 0.22764901]\n",
            "[0.14072848 0.15149007 0.16142384 0.17798013 0.19039735 0.20115894\n",
            " 0.20115894 0.21688742 0.22764901 0.24254967]\n",
            "[0.15149007 0.16142384 0.17798013 0.19039735 0.20115894 0.20115894\n",
            " 0.21688742 0.22764901 0.24254967 0.25165563]\n",
            "[0.16142384 0.17798013 0.19039735 0.20115894 0.20115894 0.21688742\n",
            " 0.22764901 0.24254967 0.25165563 0.26738411]\n",
            "[0.17798013 0.19039735 0.20115894 0.20115894 0.21688742 0.22764901\n",
            " 0.24254967 0.25165563 0.26738411 0.28145695]\n",
            "[0.19039735 0.20115894 0.20115894 0.21688742 0.22764901 0.24254967\n",
            " 0.25165563 0.26738411 0.28145695 0.29387417]\n",
            "[0.20115894 0.20115894 0.21688742 0.22764901 0.24254967 0.25165563\n",
            " 0.26738411 0.28145695 0.29387417 0.30711921]\n",
            "[0.20115894 0.21688742 0.22764901 0.24254967 0.25165563 0.26738411\n",
            " 0.28145695 0.29387417 0.30711921 0.32201987]\n",
            "[0.21688742 0.22764901 0.24254967 0.25165563 0.26738411 0.28145695\n",
            " 0.29387417 0.30711921 0.32201987 0.33443709]\n",
            "[0.22764901 0.24254967 0.25165563 0.26738411 0.28145695 0.29387417\n",
            " 0.30711921 0.32201987 0.33443709 0.34850993]\n",
            "[0.24254967 0.25165563 0.26738411 0.28145695 0.29387417 0.30711921\n",
            " 0.32201987 0.33443709 0.34850993 0.36092715]\n",
            "[0.25165563 0.26738411 0.28145695 0.29387417 0.30711921 0.32201987\n",
            " 0.33443709 0.34850993 0.36092715 0.375     ]\n",
            "[0.26738411 0.28145695 0.29387417 0.30711921 0.32201987 0.33443709\n",
            " 0.34850993 0.36092715 0.375      0.38990066]\n",
            "[0.28145695 0.29387417 0.30711921 0.32201987 0.33443709 0.34850993\n",
            " 0.36092715 0.375      0.38990066 0.40397351]\n",
            "[0.29387417 0.30711921 0.32201987 0.33443709 0.34850993 0.36092715\n",
            " 0.375      0.38990066 0.40397351 0.4147351 ]\n",
            "[0.30711921 0.32201987 0.33443709 0.34850993 0.36092715 0.375\n",
            " 0.38990066 0.40397351 0.4147351  0.43294702]\n",
            "[0.32201987 0.33443709 0.34850993 0.36092715 0.375      0.38990066\n",
            " 0.40397351 0.4147351  0.43294702 0.44536424]\n",
            "[0.33443709 0.34850993 0.36092715 0.375      0.38990066 0.40397351\n",
            " 0.4147351  0.43294702 0.44536424 0.45695364]\n",
            "[0.34850993 0.36092715 0.375      0.38990066 0.40397351 0.4147351\n",
            " 0.43294702 0.44536424 0.45695364 0.47433775]\n",
            "[0.36092715 0.375      0.38990066 0.40397351 0.4147351  0.43294702\n",
            " 0.44536424 0.45695364 0.47433775 0.48509934]\n",
            "[0.375      0.38990066 0.40397351 0.4147351  0.43294702 0.44536424\n",
            " 0.45695364 0.47433775 0.48509934 0.49586093]\n",
            "[0.38990066 0.40397351 0.4147351  0.43294702 0.44536424 0.45695364\n",
            " 0.47433775 0.48509934 0.49586093 0.51407285]\n",
            "[0.40397351 0.4147351  0.43294702 0.44536424 0.45695364 0.47433775\n",
            " 0.48509934 0.49586093 0.51407285 0.52400662]\n",
            "[0.4147351  0.43294702 0.44536424 0.45695364 0.47433775 0.48509934\n",
            " 0.49586093 0.51407285 0.52400662 0.52400662]\n",
            "[0.43294702 0.44536424 0.45695364 0.47433775 0.48509934 0.49586093\n",
            " 0.51407285 0.52400662 0.52400662 0.5339404 ]\n",
            "[0.44536424 0.45695364 0.47433775 0.48509934 0.49586093 0.51407285\n",
            " 0.52400662 0.52400662 0.5339404  0.54884106]\n",
            "[0.45695364 0.47433775 0.48509934 0.49586093 0.51407285 0.52400662\n",
            " 0.52400662 0.5339404  0.54884106 0.55960265]\n",
            "[0.47433775 0.48509934 0.49586093 0.51407285 0.52400662 0.52400662\n",
            " 0.5339404  0.54884106 0.55960265 0.56870861]\n",
            "[0.48509934 0.49586093 0.51407285 0.52400662 0.52400662 0.5339404\n",
            " 0.54884106 0.55960265 0.56870861 0.57864238]\n",
            "[0.49586093 0.51407285 0.52400662 0.52400662 0.5339404  0.54884106\n",
            " 0.55960265 0.56870861 0.57864238 0.5910596 ]\n",
            "[0.51407285 0.52400662 0.52400662 0.5339404  0.54884106 0.55960265\n",
            " 0.56870861 0.57864238 0.5910596  0.60016556]\n",
            "[0.52400662 0.52400662 0.5339404  0.54884106 0.55960265 0.56870861\n",
            " 0.57864238 0.5910596  0.60016556 0.60844371]\n",
            "[0.52400662 0.5339404  0.54884106 0.55960265 0.56870861 0.57864238\n",
            " 0.5910596  0.60016556 0.60844371 0.61589404]\n",
            "[0.5339404  0.54884106 0.55960265 0.56870861 0.57864238 0.5910596\n",
            " 0.60016556 0.60844371 0.61589404 0.62748344]\n",
            "[0.54884106 0.55960265 0.56870861 0.57864238 0.5910596  0.60016556\n",
            " 0.60844371 0.61589404 0.62748344 0.6365894 ]\n",
            "[0.55960265 0.56870861 0.57864238 0.5910596  0.60016556 0.60844371\n",
            " 0.61589404 0.62748344 0.6365894  0.64486755]\n",
            "[0.56870861 0.57864238 0.5910596  0.60016556 0.60844371 0.61589404\n",
            " 0.62748344 0.6365894  0.64486755 0.64983444]\n",
            "[0.57864238 0.5910596  0.60016556 0.60844371 0.61589404 0.62748344\n",
            " 0.6365894  0.64486755 0.64983444 0.65728477]\n",
            "[0.5910596  0.60016556 0.60844371 0.61589404 0.62748344 0.6365894\n",
            " 0.64486755 0.64983444 0.65728477 0.66804636]\n",
            "[0.60016556 0.60844371 0.61589404 0.62748344 0.6365894  0.64486755\n",
            " 0.64983444 0.65728477 0.66804636 0.67384106]\n",
            "[0.60844371 0.61589404 0.62748344 0.6365894  0.64486755 0.64983444\n",
            " 0.65728477 0.66804636 0.67384106 0.68377483]\n",
            "[0.61589404 0.62748344 0.6365894  0.64486755 0.64983444 0.65728477\n",
            " 0.66804636 0.67384106 0.68377483 0.68791391]\n",
            "[0.62748344 0.6365894  0.64486755 0.64983444 0.65728477 0.66804636\n",
            " 0.67384106 0.68377483 0.68791391 0.69205298]\n",
            "[0.6365894  0.64486755 0.64983444 0.65728477 0.66804636 0.67384106\n",
            " 0.68377483 0.68791391 0.69205298 0.69784768]\n",
            "[0.64486755 0.64983444 0.65728477 0.66804636 0.67384106 0.68377483\n",
            " 0.68791391 0.69205298 0.69784768 0.70529801]\n",
            "[0.64983444 0.65728477 0.66804636 0.67384106 0.68377483 0.68791391\n",
            " 0.69205298 0.69784768 0.70529801 0.70943709]\n",
            "[0.65728477 0.66804636 0.67384106 0.68377483 0.68791391 0.69205298\n",
            " 0.69784768 0.70529801 0.70943709 0.71440397]\n",
            "[0.66804636 0.67384106 0.68377483 0.68791391 0.69205298 0.69784768\n",
            " 0.70529801 0.70943709 0.71440397 0.72350993]\n",
            "[0.67384106 0.68377483 0.68791391 0.69205298 0.69784768 0.70529801\n",
            " 0.70943709 0.71440397 0.72350993 0.72682119]\n",
            "[0.68377483 0.68791391 0.69205298 0.69784768 0.70529801 0.70943709\n",
            " 0.71440397 0.72350993 0.72682119 0.72682119]\n",
            "[0.68791391 0.69205298 0.69784768 0.70529801 0.70943709 0.71440397\n",
            " 0.72350993 0.72682119 0.72682119 0.72930464]\n",
            "[0.69205298 0.69784768 0.70529801 0.70943709 0.71440397 0.72350993\n",
            " 0.72682119 0.72682119 0.72930464 0.73261589]\n",
            "[0.69784768 0.70529801 0.70943709 0.71440397 0.72350993 0.72682119\n",
            " 0.72682119 0.72930464 0.73261589 0.73427152]\n",
            "[0.70529801 0.70943709 0.71440397 0.72350993 0.72682119 0.72682119\n",
            " 0.72930464 0.73261589 0.73427152 0.73923841]\n",
            "[0.70943709 0.71440397 0.72350993 0.72682119 0.72682119 0.72930464\n",
            " 0.73261589 0.73427152 0.73923841 0.74172185]\n",
            "[0.71440397 0.72350993 0.72682119 0.72682119 0.72930464 0.73261589\n",
            " 0.73427152 0.73923841 0.74172185 0.74172185]\n",
            "[0.72350993 0.72682119 0.72682119 0.72930464 0.73261589 0.73427152\n",
            " 0.73923841 0.74172185 0.74172185 0.74917219]\n",
            "[0.72682119 0.72682119 0.72930464 0.73261589 0.73427152 0.73923841\n",
            " 0.74172185 0.74172185 0.74917219 0.75165563]\n",
            "[0.72682119 0.72930464 0.73261589 0.73427152 0.73923841 0.74172185\n",
            " 0.74172185 0.74917219 0.75165563 0.75496689]\n",
            "[0.72930464 0.73261589 0.73427152 0.73923841 0.74172185 0.74172185\n",
            " 0.74917219 0.75165563 0.75496689 0.75413907]\n",
            "[0.73261589 0.73427152 0.73923841 0.74172185 0.74172185 0.74917219\n",
            " 0.75165563 0.75496689 0.75413907 0.75745033]\n",
            "[0.73427152 0.73923841 0.74172185 0.74172185 0.74917219 0.75165563\n",
            " 0.75496689 0.75413907 0.75745033 0.75827815]\n",
            "[0.73923841 0.74172185 0.74172185 0.74917219 0.75165563 0.75496689\n",
            " 0.75413907 0.75745033 0.75827815 0.75993377]\n",
            "[0.74172185 0.74172185 0.74917219 0.75165563 0.75496689 0.75413907\n",
            " 0.75745033 0.75827815 0.75993377 0.7615894 ]\n",
            "[0.74172185 0.74917219 0.75165563 0.75496689 0.75413907 0.75745033\n",
            " 0.75827815 0.75993377 0.7615894  0.76241722]\n"
          ]
        }
      ],
      "source": [
        "output_size = 10\n",
        "input_size = 30\n",
        "# Creating a data structure with 60 timesteps and 1 output\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "training_set = np.array(training_set)\n",
        "data_set = training_set_scaled\n",
        "\n",
        "for i in range(input_size, (len(training_set))-(output_size-1)):\n",
        "\n",
        "  X_train.append(data_set[i-input_size:i].values)\n",
        "\n",
        "  #temp = data_set[i-input_size:i, 1].values\n",
        "\n",
        "  temp = data_set.loc[i:i+output_size-1, \"x_center\"].values\n",
        "  print(temp)\n",
        "  \n",
        "  y_train.append(temp)\n",
        "\n",
        "\n",
        "  \n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNIYoGny2zBp",
        "outputId": "8e6c6895-40b6-4b30-c801-f13518d86bc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(304, 10)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iPRx_1E2_mY",
        "outputId": "a310882c-22a7-4f9a-d116-36e3dd39ad12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(304, 30, 3)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "bljyoOKqIeEw"
      },
      "outputs": [],
      "source": [
        "# Reshaping\n",
        "kac_tane = len(dataset_train.columns) \n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], kac_tane))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL2ugQz7ZWwZ",
        "outputId": "fb678b22-4b62-4255-9c7b-38c99aa0a1b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(304, 30, 3)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnDoWZDjZYMG",
        "outputId": "a05a0cab-d14b-4d59-b078-746aa2fb005b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.70228242, 0.48096026, 0.09836066],\n",
              "       [0.70228242, 0.48096026, 0.09836066],\n",
              "       [0.70228242, 0.48096026, 0.09836066],\n",
              "       [0.70228242, 0.48178808, 0.09836066],\n",
              "       [0.67162523, 0.48178808, 0.1147541 ],\n",
              "       [0.66956789, 0.48261589, 0.1147541 ],\n",
              "       [0.66956789, 0.48261589, 0.1147541 ],\n",
              "       [0.67162523, 0.48178808, 0.1147541 ],\n",
              "       [0.66956789, 0.48261589, 0.1147541 ],\n",
              "       [0.66956789, 0.48261589, 0.1147541 ],\n",
              "       [0.66956789, 0.48261589, 0.1147541 ],\n",
              "       [0.63891112, 0.48261589, 0.08196721],\n",
              "       [0.66956789, 0.48261589, 0.09836066],\n",
              "       [0.73499695, 0.48178808, 0.09836066],\n",
              "       [0.76771106, 0.48013245, 0.09836066],\n",
              "       [0.76771106, 0.48013245, 0.09836066],\n",
              "       [0.76771106, 0.47682119, 0.09836066],\n",
              "       [0.73088185, 0.47764901, 0.1147541 ],\n",
              "       [0.85251781, 0.47433775, 0.08196721],\n",
              "       [0.76359638, 0.4718543 , 0.09836066],\n",
              "       [0.70228242, 0.47019868, 0.1147541 ],\n",
              "       [0.76771106, 0.46854305, 0.1147541 ],\n",
              "       [0.76771106, 0.46688742, 0.1147541 ],\n",
              "       [0.76771106, 0.46440397, 0.1147541 ],\n",
              "       [0.84588211, 0.46109272, 0.1147541 ],\n",
              "       [0.83924656, 0.45778146, 0.1147541 ],\n",
              "       [0.83924656, 0.45778146, 0.1147541 ],\n",
              "       [0.83261086, 0.45529801, 0.1147541 ],\n",
              "       [0.7615389 , 0.45281457, 0.13114754],\n",
              "       [0.7615389 , 0.44950331, 0.13114754]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXLlBBAygp9Q",
        "outputId": "489d9b13-0c11-4205-9fd1-637c69080335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(304, 10)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBTBKp2Xi6Ts",
        "outputId": "b61247f8-ee39-45e4-aad7-2e4ca9762e8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(304, 10)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape[0], y_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rNTeO-zT0dHn"
      },
      "outputs": [],
      "source": [
        "y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G_-C1CBwp1g",
        "outputId": "3e4e8e8f-7689-416a-befa-ac56ec8200d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.44701987, 0.44288079, 0.44039735, 0.43625828, 0.43211921,\n",
              "       0.4263245 , 0.42218543, 0.41390728, 0.41142384, 0.40645695])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzPeKECExqq9",
        "outputId": "9be8f539-a576-49f0-9f8e-915b6ea1ced8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.44288079, 0.44039735, 0.43625828, 0.43211921, 0.4263245 ,\n",
              "       0.42218543, 0.41390728, 0.41142384, 0.40645695, 0.40149007])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13tn-Xlo0L-v",
        "outputId": "109b7793-11b9-4803-a136-90c3bacba8f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(304, 10)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNSTSKvK4qQc",
        "outputId": "f8ef9733-c096-458b-d684-2feb33eeecde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dA6xejl5xGNM",
        "outputId": "526b8275-2552-4894-bd1d-74c4485b01e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 11.72050541, 576.        , 245.        ])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_set[input_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKyOEwItxua_",
        "outputId": "c9a4e23f-f58d-4893-9553-9ad78dbf1c9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14pwfpoial0k",
        "outputId": "4b4ff9e9-a327-4fcd-d870-07494ee1fd62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30, 3)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape[1], len(X_train[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBlU7XUN4bxs",
        "outputId": "e2536ea8-650c-4916-edb7-a0422bdb0f6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30, 3)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_shape = (X_train.shape[1], len(X_train[0][0]))\n",
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "Cannot convert a symbolic Tensor (simple_rnn_4/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[60], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# Modeli tanmla\u001b[39;00m\n\u001b[0;32m     10\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[1;32m---> 11\u001b[0m model\u001b[39m.\u001b[39;49madd(SimpleRNN(\u001b[39m32\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m10\u001b[39;49m, \u001b[39m1\u001b[39;49m)))\n\u001b[0;32m     12\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m))\n\u001b[0;32m     14\u001b[0m \u001b[39m# Modeli derle\u001b[39;00m\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:457\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:206\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    201\u001b[0m     x \u001b[39m=\u001b[39m input_layer\u001b[39m.\u001b[39mInput(\n\u001b[0;32m    202\u001b[0m         batch_shape\u001b[39m=\u001b[39mbatch_shape, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mlayer\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_input\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    203\u001b[0m     \u001b[39m# This will build the current layer\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[39m# and create the node connecting the current layer\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     \u001b[39m# to the input layer we just created.\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m     layer(x)\n\u001b[0;32m    207\u001b[0m     set_inputs \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m set_inputs:\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:663\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m _standardize_args(inputs,\n\u001b[0;32m    658\u001b[0m                                                      initial_state,\n\u001b[0;32m    659\u001b[0m                                                      constants,\n\u001b[0;32m    660\u001b[0m                                                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants)\n\u001b[0;32m    662\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 663\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(RNN, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    665\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:925\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 925\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m    926\u001b[0m                                             input_list)\n\u001b[0;32m    928\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    929\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1117\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1116\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39menable_auto_cast_variables(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1117\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(cast_inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1119\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOperatorNotAllowedInGraphError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1120\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mYou are attempting to use Python control \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1121\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mflow in a layer that was not declared to be \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1122\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mdynamic. Pass `dynamic=True` to the class \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1123\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mconstructor.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEncountered error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e) \u001b[39m+\u001b[39m\n\u001b[0;32m   1124\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:1572\u001b[0m, in \u001b[0;36mSimpleRNN.call\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, initial_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1571\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_reset_cell_dropout_mask(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell)\n\u001b[1;32m-> 1572\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(SimpleRNN, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1573\u001b[0m       inputs, mask\u001b[39m=\u001b[39;49mmask, training\u001b[39m=\u001b[39;49mtraining, initial_state\u001b[39m=\u001b[39;49minitial_state)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:734\u001b[0m, in \u001b[0;36mRNN.call\u001b[1;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[0;32m    731\u001b[0m is_ragged_input \u001b[39m=\u001b[39m (row_lengths \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    732\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_args_if_ragged(is_ragged_input, mask)\n\u001b[1;32m--> 734\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_inputs(\n\u001b[0;32m    735\u001b[0m     inputs, initial_state, constants)\n\u001b[0;32m    737\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_reset_cell_dropout_mask(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell)\n\u001b[0;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell, StackedRNNCells):\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:862\u001b[0m, in \u001b[0;36mRNN._process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    860\u001b[0m     initial_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates\n\u001b[0;32m    861\u001b[0m \u001b[39melif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m   initial_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_initial_state(inputs)\n\u001b[0;32m    864\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(initial_state) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates):\n\u001b[0;32m    865\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mLayer has \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates)) \u001b[39m+\u001b[39m\n\u001b[0;32m    866\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m states but was passed \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(initial_state)) \u001b[39m+\u001b[39m\n\u001b[0;32m    867\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m initial states.\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:645\u001b[0m, in \u001b[0;36mRNN.get_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    643\u001b[0m dtype \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    644\u001b[0m \u001b[39mif\u001b[39;00m get_initial_state_fn:\n\u001b[1;32m--> 645\u001b[0m   init_state \u001b[39m=\u001b[39m get_initial_state_fn(\n\u001b[0;32m    646\u001b[0m       inputs\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, batch_size\u001b[39m=\u001b[39;49mbatch_size, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    647\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    648\u001b[0m   init_state \u001b[39m=\u001b[39m _generate_zero_filled_state(batch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell\u001b[39m.\u001b[39mstate_size,\n\u001b[0;32m    649\u001b[0m                                            dtype)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:1385\u001b[0m, in \u001b[0;36mSimpleRNNCell.get_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_initial_state\u001b[39m(\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1385\u001b[0m   \u001b[39mreturn\u001b[39;00m _generate_zero_filled_state_for_cell(\u001b[39mself\u001b[39;49m, inputs, batch_size, dtype)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:2968\u001b[0m, in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2966\u001b[0m   batch_size \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mshape(inputs)[\u001b[39m0\u001b[39m]\n\u001b[0;32m   2967\u001b[0m   dtype \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mdtype\n\u001b[1;32m-> 2968\u001b[0m \u001b[39mreturn\u001b[39;00m _generate_zero_filled_state(batch_size, cell\u001b[39m.\u001b[39;49mstate_size, dtype)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:2986\u001b[0m, in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   2984\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mmap_structure(create_zeros, state_size)\n\u001b[0;32m   2985\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2986\u001b[0m   \u001b[39mreturn\u001b[39;00m create_zeros(state_size)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:2981\u001b[0m, in \u001b[0;36m_generate_zero_filled_state.<locals>.create_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   2979\u001b[0m flat_dims \u001b[39m=\u001b[39m tensor_shape\u001b[39m.\u001b[39mas_shape(unnested_state_size)\u001b[39m.\u001b[39mas_list()\n\u001b[0;32m   2980\u001b[0m init_state_size \u001b[39m=\u001b[39m [batch_size_tensor] \u001b[39m+\u001b[39m flat_dims\n\u001b[1;32m-> 2981\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39;49mzeros(init_state_size, dtype\u001b[39m=\u001b[39;49mdtype)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    203\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    204\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2747\u001b[0m, in \u001b[0;36m_tag_zeros_tensor.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2746\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2747\u001b[0m   tensor \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2748\u001b[0m   tensor\u001b[39m.\u001b[39m_is_zeros_tensor \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2749\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2794\u001b[0m, in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2790\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2791\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m   2792\u001b[0m     \u001b[39m# Create a constant if it won't be very big. Otherwise create a fill\u001b[39;00m\n\u001b[0;32m   2793\u001b[0m     \u001b[39m# op to prevent serialized GraphDefs from becoming too large.\u001b[39;00m\n\u001b[1;32m-> 2794\u001b[0m     output \u001b[39m=\u001b[39m _constant_if_small(zero, shape, dtype, name)\n\u001b[0;32m   2795\u001b[0m     \u001b[39mif\u001b[39;00m output \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2796\u001b[0m       \u001b[39mreturn\u001b[39;00m output\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2732\u001b[0m, in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2730\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_if_small\u001b[39m(value, shape, dtype, name):\n\u001b[0;32m   2731\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2732\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49mprod(shape) \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m   2733\u001b[0m       \u001b[39mreturn\u001b[39;00m constant(value, shape\u001b[39m=\u001b[39mshape, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   2734\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   2735\u001b[0m     \u001b[39m# Happens when shape is a Tensor, list with Tensor elements, etc.\u001b[39;00m\n",
            "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3051\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2933\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[0;32m   2934\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2935\u001b[0m          initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2936\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2937\u001b[0m \u001b[39m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[0;32m   2938\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3049\u001b[0m \u001b[39m    10\u001b[39;00m\n\u001b[0;32m   3050\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3051\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmultiply, \u001b[39m'\u001b[39;49m\u001b[39mprod\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out,\n\u001b[0;32m   3052\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:845\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 845\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mCannot convert a symbolic Tensor (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) to a numpy array.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m This error may indicate that you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre trying to pass a Tensor to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m a NumPy call, which is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n",
            "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (simple_rnn_4/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import SimpleRNN, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Verileri olutur\n",
        "data = np.random.random((100, 10, 1))\n",
        "targets = np.random.random((100, 1))\n",
        "\n",
        "# Modeli tanmla\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(32, input_shape=(10, 1)))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Modeli derle\n",
        "model.compile(optimizer='rmsprop', loss='mse')\n",
        "\n",
        "# Modeli eit\n",
        "model.fit(data, targets, epochs=10)\n",
        "\n",
        "# Tahmin yap\n",
        "predictions = model.predict(data)\n",
        "\n",
        "# Tahminleri numpy array'ine dntr\n",
        "predictions = np.array(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znkjFyklIhqf",
        "outputId": "e1e216f5-b3e3-4758-f255-fb411eb8cd1c"
      },
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "Cannot convert a symbolic Tensor (lstm_6/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[56], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m regressor \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m      4\u001b[0m \u001b[39m# Adding the first LSTM layer and some Dropout regularisation\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m regressor\u001b[39m.\u001b[39;49madd(LSTM(units \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m,  input_shape \u001b[39m=\u001b[39;49m (X_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39mlen\u001b[39;49m(X_train[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]))))\n\u001b[0;32m      6\u001b[0m regressor\u001b[39m.\u001b[39madd(Dropout(\u001b[39m0.2\u001b[39m))\n\u001b[0;32m      8\u001b[0m \u001b[39m# Adding a second LSTM layer and some Dropout regularisation\u001b[39;00m\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:457\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 457\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    458\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:206\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    201\u001b[0m     x \u001b[39m=\u001b[39m input_layer\u001b[39m.\u001b[39mInput(\n\u001b[0;32m    202\u001b[0m         batch_shape\u001b[39m=\u001b[39mbatch_shape, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mlayer\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_input\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    203\u001b[0m     \u001b[39m# This will build the current layer\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[39m# and create the node connecting the current layer\u001b[39;00m\n\u001b[0;32m    205\u001b[0m     \u001b[39m# to the input layer we just created.\u001b[39;00m\n\u001b[1;32m--> 206\u001b[0m     layer(x)\n\u001b[0;32m    207\u001b[0m     set_inputs \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m set_inputs:\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:663\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m _standardize_args(inputs,\n\u001b[0;32m    658\u001b[0m                                                      initial_state,\n\u001b[0;32m    659\u001b[0m                                                      constants,\n\u001b[0;32m    660\u001b[0m                                                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants)\n\u001b[0;32m    662\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 663\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(RNN, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    665\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:925\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 925\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m    926\u001b[0m                                             input_list)\n\u001b[0;32m    928\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    929\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1117\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1116\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39menable_auto_cast_variables(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1117\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(cast_inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1119\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOperatorNotAllowedInGraphError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1120\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mYou are attempting to use Python control \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1121\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mflow in a layer that was not declared to be \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1122\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mdynamic. Pass `dynamic=True` to the class \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1123\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mconstructor.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEncountered error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e) \u001b[39m+\u001b[39m\n\u001b[0;32m   1124\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py:1108\u001b[0m, in \u001b[0;36mLSTM.call\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_args_if_ragged(is_ragged_input, mask)\n\u001b[0;32m   1107\u001b[0m \u001b[39m# LSTM does not support constants. Ignore it during process.\u001b[39;00m\n\u001b[1;32m-> 1108\u001b[0m inputs, initial_state, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_inputs(inputs, initial_state, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1110\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(mask, \u001b[39mlist\u001b[39m):\n\u001b[0;32m   1111\u001b[0m   mask \u001b[39m=\u001b[39m mask[\u001b[39m0\u001b[39m]\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:862\u001b[0m, in \u001b[0;36mRNN._process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    860\u001b[0m     initial_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates\n\u001b[0;32m    861\u001b[0m \u001b[39melif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m   initial_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_initial_state(inputs)\n\u001b[0;32m    864\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(initial_state) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates):\n\u001b[0;32m    865\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mLayer has \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstates)) \u001b[39m+\u001b[39m\n\u001b[0;32m    866\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m states but was passed \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(initial_state)) \u001b[39m+\u001b[39m\n\u001b[0;32m    867\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m initial states.\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:645\u001b[0m, in \u001b[0;36mRNN.get_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    643\u001b[0m dtype \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    644\u001b[0m \u001b[39mif\u001b[39;00m get_initial_state_fn:\n\u001b[1;32m--> 645\u001b[0m   init_state \u001b[39m=\u001b[39m get_initial_state_fn(\n\u001b[0;32m    646\u001b[0m       inputs\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, batch_size\u001b[39m=\u001b[39;49mbatch_size, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    647\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    648\u001b[0m   init_state \u001b[39m=\u001b[39m _generate_zero_filled_state(batch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell\u001b[39m.\u001b[39mstate_size,\n\u001b[0;32m    649\u001b[0m                                            dtype)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:2523\u001b[0m, in \u001b[0;36mLSTMCell.get_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2522\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_initial_state\u001b[39m(\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 2523\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_generate_zero_filled_state_for_cell(\n\u001b[0;32m   2524\u001b[0m       \u001b[39mself\u001b[39;49m, inputs, batch_size, dtype))\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:2968\u001b[0m, in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2966\u001b[0m   batch_size \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mshape(inputs)[\u001b[39m0\u001b[39m]\n\u001b[0;32m   2967\u001b[0m   dtype \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mdtype\n\u001b[1;32m-> 2968\u001b[0m \u001b[39mreturn\u001b[39;00m _generate_zero_filled_state(batch_size, cell\u001b[39m.\u001b[39;49mstate_size, dtype)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:2984\u001b[0m, in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   2981\u001b[0m   \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39mzeros(init_state_size, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m   2983\u001b[0m \u001b[39mif\u001b[39;00m nest\u001b[39m.\u001b[39mis_sequence(state_size):\n\u001b[1;32m-> 2984\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39;49mmap_structure(create_zeros, state_size)\n\u001b[0;32m   2985\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2986\u001b[0m   \u001b[39mreturn\u001b[39;00m create_zeros(state_size)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:635\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m flat_structure \u001b[39m=\u001b[39m [flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure]\n\u001b[0;32m    632\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    634\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 635\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    636\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:635\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    631\u001b[0m flat_structure \u001b[39m=\u001b[39m [flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure]\n\u001b[0;32m    632\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    634\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 635\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    636\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py:2981\u001b[0m, in \u001b[0;36m_generate_zero_filled_state.<locals>.create_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   2979\u001b[0m flat_dims \u001b[39m=\u001b[39m tensor_shape\u001b[39m.\u001b[39mas_shape(unnested_state_size)\u001b[39m.\u001b[39mas_list()\n\u001b[0;32m   2980\u001b[0m init_state_size \u001b[39m=\u001b[39m [batch_size_tensor] \u001b[39m+\u001b[39m flat_dims\n\u001b[1;32m-> 2981\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39;49mzeros(init_state_size, dtype\u001b[39m=\u001b[39;49mdtype)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    203\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    204\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    205\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2747\u001b[0m, in \u001b[0;36m_tag_zeros_tensor.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2746\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2747\u001b[0m   tensor \u001b[39m=\u001b[39m fun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2748\u001b[0m   tensor\u001b[39m.\u001b[39m_is_zeros_tensor \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   2749\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2794\u001b[0m, in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2790\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2791\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m   2792\u001b[0m     \u001b[39m# Create a constant if it won't be very big. Otherwise create a fill\u001b[39;00m\n\u001b[0;32m   2793\u001b[0m     \u001b[39m# op to prevent serialized GraphDefs from becoming too large.\u001b[39;00m\n\u001b[1;32m-> 2794\u001b[0m     output \u001b[39m=\u001b[39m _constant_if_small(zero, shape, dtype, name)\n\u001b[0;32m   2795\u001b[0m     \u001b[39mif\u001b[39;00m output \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2796\u001b[0m       \u001b[39mreturn\u001b[39;00m output\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2732\u001b[0m, in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2730\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_if_small\u001b[39m(value, shape, dtype, name):\n\u001b[0;32m   2731\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2732\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49mprod(shape) \u001b[39m<\u001b[39m \u001b[39m1000\u001b[39m:\n\u001b[0;32m   2733\u001b[0m       \u001b[39mreturn\u001b[39;00m constant(value, shape\u001b[39m=\u001b[39mshape, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mname)\n\u001b[0;32m   2734\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   2735\u001b[0m     \u001b[39m# Happens when shape is a Tensor, list with Tensor elements, etc.\u001b[39;00m\n",
            "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3051\u001b[0m, in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2933\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[0;32m   2934\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2935\u001b[0m          initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2936\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2937\u001b[0m \u001b[39m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[0;32m   2938\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3049\u001b[0m \u001b[39m    10\u001b[39;00m\n\u001b[0;32m   3050\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3051\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmultiply, \u001b[39m'\u001b[39;49m\u001b[39mprod\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out,\n\u001b[0;32m   3052\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
            "File \u001b[1;32me:\\Venvs\\venv_mantis\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:845\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 845\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mCannot convert a symbolic Tensor (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) to a numpy array.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m This error may indicate that you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre trying to pass a Tensor to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m a NumPy call, which is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname))\n",
            "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (lstm_6/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
          ]
        }
      ],
      "source": [
        "# Initialising the RNN\n",
        "regressor = Sequential()\n",
        "\n",
        "# Adding the first LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50,  input_shape = (X_train.shape[1], len(X_train[0][0]))))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding the output layer\n",
        "regressor.add(Dense(units = output_size))\n",
        "\n",
        "# Compiling the RNN\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Fitting the RNN to the Training set\n",
        "regressor.fit(X_train, y_train, epochs = 10, batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "UEAbz2rlNWLg"
      },
      "outputs": [],
      "source": [
        "regressor.save(distance_folder_path+ \"/saved_models/lstm_x_center.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1wi4hXDeLj-"
      },
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "b2B8P3eWOCQO"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "regressor = keras.models.load_model(distance_folder_path+ \"/saved_models/lstm_x_center.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "eRDseUPtOZdQ"
      },
      "outputs": [],
      "source": [
        "dataset_train = pd.read_csv(distance_folder_path+ '/datasets/old/df_rnn.csv')\n",
        "dataset_x_center = dataset_train['x_center'].values\n",
        "inputs_x_center = dataset_x_center.reshape(-1,1)\n",
        "\n",
        "dataset_y_center = dataset_train['y_center'].values\n",
        "inputs_y_center = dataset_y_center.reshape(-1,1)\n",
        "\n",
        "dataset_distance = dataset_train['distance'].values\n",
        "inputs_distance = dataset_distance.reshape(-1,1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAXPkW5njgR9",
        "outputId": "9a1343be-6283-4697-9fc7-46c6cab01824"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(343, 1)"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs_x_center.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ke_xoO3uKEG",
        "outputId": "332db598-1205-4be7-9ad0-5b0b94c2a580"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(inputs_x_center)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "I9Ch6Tgmkvoe"
      },
      "outputs": [],
      "source": [
        "normalization_path = distance_folder_path + \"/datasets/old/transform\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSlYcodybd05",
        "outputId": "42aaf04c-44ca-4cf7-a2cf-e547b083bb3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scalar.transform(test_set_scaled_x_center) [0.48096026]\n"
          ]
        }
      ],
      "source": [
        "scalar = joblib.load(normalization_path+\"x_center\"+\"_transform.save\")\n",
        "test_set_scaled_x_center = scalar.transform(inputs_x_center)\n",
        "\n",
        "print(\"scalar.transform(test_set_scaled_x_center)\",test_set_scaled_x_center[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfDfOWvYkkBO",
        "outputId": "3057e594-0bb0-4454-c66e-41f19791c0f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scalar.transform(test_set_scaled_y_center) [0.09836066]\n"
          ]
        }
      ],
      "source": [
        "scalar = joblib.load(normalization_path+\"y_center\"+\"_transform.save\")\n",
        "test_set_scaled_y_center = scalar.transform(inputs_y_center)\n",
        "\n",
        "print(\"scalar.transform(test_set_scaled_y_center)\",test_set_scaled_y_center[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InLsXJBWlcbo",
        "outputId": "479086b0-597c-4716-c30a-256b02a0d106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scalar.transform(test_set_scaled_distance) [0.70228242]\n"
          ]
        }
      ],
      "source": [
        "scalar = joblib.load(normalization_path+\"distance\"+\"_transform.save\")\n",
        "test_set_scaled_distance = scalar.transform(inputs_distance )\n",
        "\n",
        "print(\"scalar.transform(test_set_scaled_distance)\",test_set_scaled_distance[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "4UVS9zMYbUMl"
      },
      "outputs": [],
      "source": [
        "# Creating a data structure with 60 timesteps and 1 output\n",
        "\n",
        "X_Test = []\n",
        "y_test = []\n",
        "for i in range(input_size, (len(training_set))-(output_size-1)):\n",
        "    X_Test.append([test_set_scaled_x_center[i-input_size:i, 0], test_set_scaled_y_center[i-input_size:i, 0], test_set_scaled_distance[i-input_size:i, 0]])\n",
        "    #y_test.append(test_set_scaled[i:i+output_size, 0])\n",
        "    y_test.append(test_set_scaled_x_center[i, 0])\n",
        "X_Test, y_test = np.array(X_Test), np.array(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBnOD4c3msA6",
        "outputId": "94804965-3bc8-47cb-ed85-56a20c8d1506"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(304, 3, 30)"
            ]
          },
          "execution_count": 184,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_Test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "y6edr91q8l2f",
        "outputId": "87e8abc8-6678-4d7a-f227-0122bf03d805"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-183-6bad7a1dd2ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_Test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_Test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_Test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_Test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    296\u001b[0m            [5, 6]])\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 27360 into shape (304,3,1)"
          ]
        }
      ],
      "source": [
        "X_Test = np.reshape(X_Test, (X_Test.shape[0], X_Test.shape[1], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnIkM8OQ8kcv",
        "outputId": "f12b07a4-0b1a-45a6-bf1a-92ca2738fd43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(304, 1)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VbLqrnZck3l",
        "outputId": "cbc8d8e1-4286-4d5d-8103-0a4c26739a8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30, 1)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_Test[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T94CFTncuJ0",
        "outputId": "a6158932-bf41-4837-d528-f42920ee0174"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.48096026])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_Test[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHlHwb0Ccx5U",
        "outputId": "ac4c4372-ebd4-42db-b174-2804ce0387ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.48096026])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_Test[1][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N02RQwoRQB3r",
        "outputId": "01c48df5-d04b-4d9e-a500-5ccc1cefca5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(304, 1)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ8EqLUsguga",
        "outputId": "ebe3d2ed-7a2b-4207-e3cf-673dbde090ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.44701987])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmaQvn3e9WDz",
        "outputId": "bfb2243a-eed8-4827-faa3-6bcb11a5f7f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.4791202 , 0.47696105, 0.46170077, 0.49268794, 0.4743422 ,\n",
              "       0.5004336 , 0.46469125, 0.47653648, 0.4648028 , 0.4636717 ],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_distance = regressor.predict(X_Test)\n",
        "predicted_distance[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qn3i_xsRdfT5"
      },
      "outputs": [],
      "source": [
        "predicted_distance = predicted_distance[:,0]\n",
        "predicted_distance = predicted_distance.reshape(-1,1)\n",
        "predicted_distance = scalar.inverse_transform(predicted_distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulX01VdW747H"
      },
      "outputs": [],
      "source": [
        "y_test = scalar.inverse_transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "vHOsrvXldpoE",
        "outputId": "925aa6fd-aaa9-4dfb-859f-e7c44c6b00a6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualising the results\n",
        "plt.plot(y_test, color = 'red', label = 'Real drone movement')\n",
        "plt.plot(predicted_distance, color = 'blue', label = 'Predicted ')\n",
        "plt.title('Drone movement Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Drone x center')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_mantis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "fbe40dc30a0fa891532f70b043861e838a065b0c689212cb960b39fbe5664062"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
